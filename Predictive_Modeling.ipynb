{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Computational Biology Project for CHE-293(Applied Bioinformatics) at San Jose State University"
      ],
      "metadata": {
        "id": "ju73GaYI_jv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To study switches (proteins with flexible sheaths that “switch” states in response to stimuli) through machine learning techniques and predictive modeling on the Bondugula dataset"
      ],
      "metadata": {
        "id": "wMaR-Jv0_EOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJKPr7VF6pf8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve,  accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files_uploaded = files.upload()"
      ],
      "metadata": {
        "id": "u_iHTxNu6693"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"bondugula_JDO_20230125_SLIM (1).csv\")\n",
        "data.columns"
      ],
      "metadata": {
        "id": "_-LPA3vT6-Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a column is_switch based on HAS_H, HAS_S, HAS_O, HAS_U."
      ],
      "metadata": {
        "id": "cS0_v16p7HRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding is_switch column"
      ],
      "metadata": {
        "id": "QDHJwSFS7KtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_data['num_X'] = raw_data['HAS_H'] + raw_data['HAS_S'] + raw_data['HAS_O'] + raw_data['HAS_U']\n",
        "raw_data['is_switch'] = np.where(raw_data['num_X'] > 1, 1, 0)\n",
        "percent_switches = (raw_data['is_switch'].sum())/(len(raw_data['is_switch']))\n",
        "print(\"Percentage of proteins in dataset that are switches is \" + str(round(percent_switches*100,2)) + \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI-KvhGc8gY9",
        "outputId": "91b923c6-871f-4306-b141-c99863e626e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of proteins in dataset that are switches is 16.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing E6.1, E20.1, E22, ProteinID and Res columns"
      ],
      "metadata": {
        "id": "mrQXDon97Snx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = raw_data.drop(['E6.1', 'E20.1','Res','E22', 'ProteinID'], axis=1)\n",
        "data.columns"
      ],
      "metadata": {
        "id": "ut73sS657TWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "IgjpXRHU7WnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_column(quant_column):\n",
        "    magnitude = np.sqrt((np.power(quant_column,2)).sum())\n",
        "    return quant_column/magnitude\n",
        "\n",
        "def standardize_column(quant_column):\n",
        "    U = np.mean(quant_column)\n",
        "    o = np.std(quant_column)\n",
        "    return (quant_column - U)/o\n",
        "\n",
        "def squarevalue (data,quant_column):\n",
        "    squared_column=data[quant_column]**2\n",
        "    return squared_column\n",
        "\n",
        "def scaling (data,quant_column):\n",
        "    min_val=data[quant_column].min()\n",
        "    max_val=data[quant_column].max()\n",
        "    scaled_column=(data[quant_column]-min_val)/((max_val)-(min_val))\n",
        "    return scaled_column"
      ],
      "metadata": {
        "id": "hM5_xwi97V6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = data.copy()\n",
        "processed_data['squared_E6']=squarevalue(data,'E6')\n",
        "processed_data['squared_E20']=squarevalue(data,'E20')\n",
        "processed_data['squared_isUnstruct']=squarevalue(data,'isUnstruct')\n",
        "processed_data['squared_Vkbat']=squarevalue(data,'Vkbat')\n",
        "processed_data['scaledE6']=scaling(data,'E6')\n",
        "processed_data['scaledE20']=scaling(data,'E20')\n",
        "processed_data['scaled_isUnstruct']=scaling(data,'isUnstruct')\n",
        "processed_data['scaled_Vkbat']=squarevalue(data,'Vkbat')\n",
        "#processed_data.head(20)"
      ],
      "metadata": {
        "id": "reTzjcTj7dPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting Residue data to numeric values"
      ],
      "metadata": {
        "id": "I7-Nl0Hl7ghG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['Res_numeric'] = processed_data['Residue'].apply(lambda x: ord(str(x)))\n",
        "processed_data['squared_Res_numeric']=squarevalue(data,'Res_numeric')\n",
        "processed_data['scaled_Res_numeric']=scaling(data,'Res_numeric')\n",
        "#processed_data['Res_numeric'] = standardize_column(processed_data['Res_numeric'])"
      ],
      "metadata": {
        "id": "uto7S_pZ7kGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot Encoder"
      ],
      "metadata": {
        "id": "kfoU0iFe7nAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ohe= OneHotEncoder()\n",
        "ohe_features_array = ohe.fit_transform(processed_data[['chou_fasman', 'sspro_5', 'gor4', 'dsc', 'jnet', 'psipred']]).toarray()\n",
        "feature_labels = ohe.categories_\n",
        "\n",
        "feature_labels = ohe.get_feature_names_out(['chou_fasman', 'sspro_5', 'gor4', 'dsc', 'jnet', 'psipred'])\n",
        "print(feature_labels)\n",
        "\n",
        "ohe_df = pd.DataFrame(ohe_features_array, columns = feature_labels)\n",
        "#ohe_df.tail(10)"
      ],
      "metadata": {
        "id": "5mDbROHX7mSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = processed_data.reset_index()"
      ],
      "metadata": {
        "id": "u-N_aVAq7rbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mo = pd.concat([processed_data, ohe_df],axis=1)\n",
        "df_mo = df_mo.drop(columns=['index'])\n",
        "df_mo=df_mo.drop(columns=['Unnamed: 0'])\n",
        "df_mo=df_mo.dropna()  #regression doesn't work with empty cells. Have to remove.\n",
        "df_mo.head(20)"
      ],
      "metadata": {
        "id": "s_CYu-4Y7tl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if there are empty cells"
      ],
      "metadata": {
        "id": "5_QujpDT7ynk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_cell_count=df_mo.isnull().sum()\n",
        "print(\"empty cell count in column:\")\n",
        "print(empty_cell_count)"
      ],
      "metadata": {
        "id": "QnnoNxwG7yPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest\n"
      ],
      "metadata": {
        "id": "xjErdWvI8Ci1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting with true data\n",
        "\n",
        "Inclusion of 'HAS_H','HAS_S','HAS_O','HAS_U' will give the score 1.0 since they are the true values."
      ],
      "metadata": {
        "id": "Wj8SIhxI8Dpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_quant_features = ['E20','E6','isUnstruct','Vkbat', 'HAS_H','HAS_S','HAS_O','HAS_U']\n",
        "\n",
        "target = \"is_switch\""
      ],
      "metadata": {
        "id": "Z1eAb1HV8KUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(df_mo, test_size=0.25, random_state=1)\n",
        "X_train = train_data[simple_quant_features]\n",
        "y_train = train_data[target]\n",
        "X_test = test_data[simple_quant_features]\n",
        "y_test = test_data[target]"
      ],
      "metadata": {
        "id": "UC_Kxjo_8Mu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators = 25, oob_score = True)\n",
        "rf_model.fit(train_data[simple_quant_features], train_data[target])\n",
        "rf_model.get_params()"
      ],
      "metadata": {
        "id": "5cTRnSsx8OyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Out of bag estimate score: {rf_model.oob_score_}\")\n",
        "print(f\"Train Score: {rf_model.score(train_data[simple_quant_features], train_data[target])}\")\n",
        "print(f\"Test Score: {rf_model.score(test_data[simple_quant_features], test_data[target])}\")"
      ],
      "metadata": {
        "id": "aQjDxUEL8Sds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling with processed data"
      ],
      "metadata": {
        "id": "dzEwhs_c8WOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_sets = [\n",
        "  ['squared_E20','HAS_H','HAS_S','HAS_U','HAS_O'],\n",
        "  ['E6','isUnstruct','Vkbat'],\n",
        "  ['E6','isUnstruct'],\n",
        "  ['E6','Res_numeric','isUnstruct','Vkbat'],\n",
        "  ['E6','Res_numeric','isUnstruct'],\n",
        "  ['E6','Res_numeric','Vkbat'],\n",
        "  ['E6','Res_numeric'],\n",
        "  ['E6','Vkbat'],\n",
        "  ['E6'],\n",
        "  ['E20','isUnstruct','Vkbat'],\n",
        "  ['E20','isUnstruct'],\n",
        "  ['E20','Res_numeric','isUnstruct','Vkbat'],\n",
        "  ['E20','Res_numeric','isUnstruct'],\n",
        "  ['E20','Res_numeric','Vkbat'],\n",
        "  ['E20','Res_numeric'],\n",
        "  ['E20','Vkbat'],\n",
        "  ['E20'],\n",
        "  ['isUnstruct','Res_numeric'],\n",
        "  ['isUnstruct','Vkbat'],\n",
        "  ['isUnstruct'],\n",
        "  ['Res_numeric','isUnstruct','Vkbat'],\n",
        "  ['Res_numeric'],\n",
        "  ['Vkbat','Res_numeric'],\n",
        "  ['Vkbat'],\n",
        "  ['squared_E6','scaledE6','squared_E20','scaledE20'],\n",
        "  ['squared_E6','scaledE6'],\n",
        "  ['squared_E20','scaledE20'],\n",
        "  ['squared_E6','squared_Vkbat'],\n",
        "  ['squared_E20','squared_Vkbat'],\n",
        "  ['scaled_Vkbat'],\n",
        "  ['scaled_isUnstrct'],\n",
        "  ['squared_isUnstruct','scaled_isUnstruct']\n",
        " ]"
      ],
      "metadata": {
        "id": "zeHYGLTq8cuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_models = []\n",
        "roc_curves=[]\n",
        "prob_scores=[]\n",
        "\n",
        "for i, features in enumerate(feature_sets):\n",
        "    print(f'{features=}')\n",
        "\n",
        "    # Fit Random forest\n",
        "    rf_model = RandomForestClassifier(n_estimators = 25, oob_score = True)\n",
        "    rf_model.fit(train_data[features], train_data[target])\n",
        "\n",
        "    print(f\"Out of bag estimate score: {rf_model.oob_score_}\")\n",
        "    print(f\"Train Score: {rf_model.score(train_data[features], train_data[target])}\")\n",
        "    print(f\"Test Score: {rf_model.score(test_data[features], test_data[target])}\")\n",
        "\n",
        "    rf_model_scores = rf_model.predict_proba(test_data[features])[:,1] # extracts probabilities of class 1 (being a switch)\n",
        "    fpr_reg, tpr_reg, thresholds_reg = roc_curve(test_data[target], rf_model_scores)\n",
        "    prob_scores.append((rf_model_scores, f\"Random Forest {i}\"))"
      ],
      "metadata": {
        "id": "-AzilDqn8ofp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "for (rfmodel_prob_scores, label) in prob_scores:\n",
        "    # Compute the ROC curve data points using the correct variable\n",
        "    fpr_reg, tpr_reg, thresholds_reg = roc_curve(test_data[target], rfmodel_prob_scores)\n",
        "    # Plot the ROC curve for this model\n",
        "    plt.plot(fpr_reg, tpr_reg, label=f\"{label} (AUC = {roc_auc_score(test_data[target], rfmodel_prob_scores):.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "\n",
        "# Move the legend outside the plot to avoid covering the ROC curves\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Random Forest Models')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "\n",
        "# Show the plot with all ROC curves\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KlUMNYNE8th8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n"
      ],
      "metadata": {
        "id": "KKvrZOcD8v23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting with true data"
      ],
      "metadata": {
        "id": "tF25ZI9i84aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_logistic_model = LogisticRegression().fit(train_data[simple_quant_features], y_train)"
      ],
      "metadata": {
        "id": "i6mFyHZe8zBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = true_logistic_model.predict(X_test)\n",
        "prob_preds = true_logistic_model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "cQK_PTQJ86xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[print(f\"{feat}: {coef:.4f}\") for feat, coef in zip(simple_quant_features, true_logistic_model.coef_[0])];\n",
        "print(f\"Intercept: {true_logistic_model.intercept_[0]}\")\n",
        "print(f\"Error: {(preds - y_test).sum()}\")\n",
        "print(f\"Score: {true_logistic_model.score(X_test, y_test)}\")"
      ],
      "metadata": {
        "id": "JoGxzzqT88qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "With processed data"
      ],
      "metadata": {
        "id": "RSWhh5iN9AwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_models = []\n",
        "roc_curves=[]\n",
        "prob_scores=[]\n",
        "for i, features in enumerate(feature_sets):\n",
        "    print(f'{features=}')\n",
        "\n",
        "    # Fit Logistic Regression model\n",
        "    logistic_model = LogisticRegression().fit(train_data[features], train_data[target])\n",
        "\n",
        "    # Print coefficients and intercept\n",
        "    [print(f\"{feature}: {coefficient:.4f}\") for feature, coefficient in zip(features, logistic_model.coef_[0])]\n",
        "    print(f\"Intercept: {logistic_model.intercept_[0]:.4f}\")\n",
        "\n",
        "    score = logistic_model.score(test_data[features], test_data[target])\n",
        "    print(f\"Score: {score:.6f}\")\n",
        "    print('')\n",
        "\n",
        "    auc = np.round(roc_auc_score(test_data[target], logistic_model.predict(test_data[features])), 4)\n",
        "    print(\"Auc for our sample data is {}\".format(auc))\n",
        "    print(\"=\"*300)\n",
        "    print('')\n",
        "\n",
        "    logmodel_prob_scores = logistic_model.predict_proba(test_data[features])[:, 1]\n",
        "    prob_scores.append((logmodel_prob_scores, f\"Logistic Regression {i}\"))"
      ],
      "metadata": {
        "id": "sJdXuTwN9Cy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking count in test data for is_switch\n",
        "sum(test_data[target]  == 0) / len(test_data[target])"
      ],
      "metadata": {
        "id": "srBMiwVK9JxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "for (logmodel_prob_scores, label) in prob_scores:\n",
        "    fpr, tpr, _ = roc_curve(test_data[target], logmodel_prob_scores)\n",
        "    roc_curves.append((fpr, tpr, label))\n",
        "    plt.plot(fpr, tpr, label=f\"{label} (AUC = {roc_auc_score(test_data[target], logmodel_prob_scores):.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Logistic Regression Models')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AgIuFYoH9MDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Model"
      ],
      "metadata": {
        "id": "iuffgKGb9OEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_models = []\n",
        "roc_curves_svm = []\n",
        "prob_scores_svm = []\n",
        "\n",
        "for i, features in enumerate(feature_sets):\n",
        "    print(f'{features=}')\n",
        "\n",
        "\n",
        "    svm_model = LinearSVC().fit(train_data[features], train_data[target])\n",
        "\n",
        "\n",
        "    score = svm_model.score(test_data[features], test_data[target])\n",
        "    print(f\"Score: {score:.6f}\")\n",
        "    print('')\n",
        "\n",
        "    auc_svm = np.round(roc_auc_score(test_data[target], svm_model.decision_function(test_data[features])), 3)\n",
        "    print(\"AUC for our sample data is {}\".format(auc_svm))\n",
        "    print(\"=\" * 300)\n",
        "    print('')\n",
        "\n",
        "    # Store decision function values for ROC curve\n",
        "    svm_decision_function = svm_model.decision_function(test_data[features])\n",
        "    prob_scores_svm.append((svm_decision_function, f\"Linear SVM {i}\"))\n",
        "\n",
        "# Plot ROC curves for all Linear SVM models\n",
        "plt.figure(figsize=(8, 8))\n",
        "for (svm_decision_function, label) in prob_scores_svm:\n",
        "    fpr, tpr, _ = roc_curve(test_data[target], svm_decision_function)\n",
        "    roc_curves_svm.append((fpr, tpr, label))\n",
        "    plt.plot(fpr, tpr, label=f\"{label} (AUC = {roc_auc_score(test_data[target], svm_decision_function):.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Linear SVM Models')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F76L1MqD9Plm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee4RHOet9Tlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}